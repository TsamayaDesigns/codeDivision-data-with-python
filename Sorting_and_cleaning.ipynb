{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TsamayaDesigns/codeDivision-data-with-python/blob/main/Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first.\n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g.\n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make\n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df` *original dataframe, df, will be as it was - unsorted*\n",
        "\n",
        "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score\n",
        "---\n",
        "\n",
        "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n",
        "**Test output**:  \n",
        "The lowest score (displayed first) is 2.839, Togo  \n",
        "The highest score (displayed last) is 7.587, Switzerland  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4980cc-1db2-4b42-acd4-1f953a006689"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_excel_data():\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  return df\n",
        "\n",
        "data = get_excel_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Display first 5 rows of data\n",
        "  orig_data = data.head()\n",
        "\n",
        "  # 2. Sort the data by Happiness Score in ascending order & display the sorted table\n",
        "  sorted_data = data.sort_values(\"Happiness Score\", ascending = True)\n",
        "\n",
        "  return {\n",
        "      \"1. Display first 5 rows of data\": orig_data,\n",
        "      \"2. Display the sorted data - (by Happiness Score, sorted: ascending order)\": sorted_data,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 1 - Get data & Sort by Happiness Score\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 1 - Get data & Sort by Hapiness Score\n",
            "\n",
            "1. Display first 5 rows of data:\n",
            "       Country          Region  Happiness Rank  Happiness Score  Standard Error  Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  Trust (Government Corruption)  Generosity  Dystopia Residual\n",
            "0  Switzerland  Western Europe               1            7.587         0.03411                   1.39651  1.34951                   0.94143  0.66557                        0.41978     0.29678            2.51738\n",
            "1      Iceland  Western Europe               2            7.561         0.04884                   1.30232  1.40223                   0.94784  0.62877                        0.14145     0.43630            2.70201\n",
            "2      Denmark  Western Europe               3            7.527         0.03328                   1.32548  1.36058                   0.87464  0.64938                        0.48357     0.34139            2.49204\n",
            "3       Norway  Western Europe               4            7.522         0.03880                   1.45900  1.33095                   0.88521  0.66973                        0.36503     0.34699            2.46531\n",
            "4       Canada   North America               5            7.427         0.03553                   1.32629  1.32261                   0.90563  0.63297                        0.32957     0.45811            2.45176\n",
            "\n",
            "2. Display the sorted data - (by Happiness Score, sorted: ascending order):\n",
            "         Country                           Region  Happiness Rank  Happiness Score  Standard Error  Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  Trust (Government Corruption)  Generosity  Dystopia Residual\n",
            "157         Togo               Sub-Saharan Africa             158            2.839         0.06727                   0.20868  0.13995                   0.28443  0.36453                        0.10731     0.16681            1.56726\n",
            "156      Burundi               Sub-Saharan Africa             157            2.905         0.08658                   0.01530  0.41587                   0.22396  0.11850                        0.10062     0.19727            1.83302\n",
            "155        Syria  Middle East and Northern Africa             156            3.006         0.05015                   0.66320  0.47489                   0.72193  0.15684                        0.18906     0.47179            0.32858\n",
            "154        Benin               Sub-Saharan Africa             155            3.340         0.03656                   0.28665  0.35386                   0.31910  0.48450                        0.08010     0.18260            1.63328\n",
            "153       Rwanda               Sub-Saharan Africa             154            3.465         0.03464                   0.22208  0.77370                   0.42864  0.59201                        0.55191     0.22628            0.67042\n",
            "..           ...                              ...             ...              ...             ...                       ...      ...                       ...      ...                            ...         ...                ...\n",
            "4         Canada                    North America               5            7.427         0.03553                   1.32629  1.32261                   0.90563  0.63297                        0.32957     0.45811            2.45176\n",
            "3         Norway                   Western Europe               4            7.522         0.03880                   1.45900  1.33095                   0.88521  0.66973                        0.36503     0.34699            2.46531\n",
            "2        Denmark                   Western Europe               3            7.527         0.03328                   1.32548  1.36058                   0.87464  0.64938                        0.48357     0.34139            2.49204\n",
            "1        Iceland                   Western Europe               2            7.561         0.04884                   1.30232  1.40223                   0.94784  0.62877                        0.14145     0.43630            2.70201\n",
            "0    Switzerland                   Western Europe               1            7.587         0.03411                   1.39651  1.34951                   0.94143  0.66557                        0.41978     0.29678            2.51738\n",
            "\n",
            "[158 rows x 12 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows\n",
        "---\n",
        "\n",
        "1. Sort the data by Health (Life Expectancy) and Economy (GDP per Capita) in ascending order\n",
        "2. display the first 5 rows of sorted data\n",
        "\n",
        "**Test output**:  \n",
        "Records 122, 127, 147, 100, 96"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2309735c-2420-441b-9f50-91092ee1b774"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_excel_data():\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  return df\n",
        "\n",
        "data = get_excel_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Sort the data by Health (Life Expectancy) and Economy (GDP per Capita) in ascending order\n",
        "  sort_data = data.sort_values(by = [\"Health (Life Expectancy)\", \"Economy (GDP per Capita)\"], ascending = [True, True])\n",
        "\n",
        "  # 2. Display the first 5 rows of sorted data\n",
        "  sorted_data_hd = sort_data.head()\n",
        "\n",
        "  return {\n",
        "      \"1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order (first 5 rows of sorted data) \": sorted_data_hd,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 2 - Sort by multiple columns & display the first 5 rows\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 2 - Sort by multiple columns & display the first 5 rows\n",
            "\n",
            "1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order (first 5 rows of sorted data) :\n",
            "                      Country              Region  Happiness Rank  Happiness Score  Standard Error  Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  Trust (Government Corruption)  Generosity  Dystopia Residual\n",
            "122              Sierra Leone  Sub-Saharan Africa             123            4.507         0.07068                   0.33024  0.95571                   0.00000  0.40840                        0.08786     0.21488            2.51009\n",
            "127                  Botswana  Sub-Saharan Africa             128            4.332         0.04934                   0.99355  1.10464                   0.04776  0.49495                        0.12474     0.10461            1.46181\n",
            "147  Central African Republic  Sub-Saharan Africa             148            3.678         0.06112                   0.07850  0.00000                   0.06699  0.48879                        0.08289     0.23835            2.72230\n",
            "100                 Swaziland  Sub-Saharan Africa             101            4.867         0.08742                   0.71206  1.07284                   0.07566  0.30658                        0.03060     0.18259            2.48676\n",
            "96                    Lesotho  Sub-Saharan Africa              97            4.898         0.09438                   0.37545  1.04103                   0.07612  0.31767                        0.12504     0.16388            2.79832\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order\n",
        "---\n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n",
        "**Test output**:\n",
        "136, 117, 95, 101, 111 Country and Region columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356d7d66-5dac-4e51-f9a9-0064143f9993"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_excel_data():\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  return df\n",
        "\n",
        "data = get_excel_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Sort the data by Freedom and Trust (Government Corruption) in descending order. Show the Country and Region only for the last five rows\n",
        "  sort_data = data.sort_values(by = [\"Freedom\", \"Trust (Government Corruption)\"], ascending = False)[[\"Country\", \"Region\"]].tail()\n",
        "\n",
        "  return {\n",
        "      \"1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order\": sort_data,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 3 - Sorting in descending order\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 3 - Sorting in descending order\n",
            "\n",
            "1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order:\n",
            "                    Country                           Region\n",
            "136                  Angola               Sub-Saharan Africa\n",
            "117                   Sudan               Sub-Saharan Africa\n",
            "95   Bosnia and Herzegovina       Central and Eastern Europe\n",
            "101                  Greece                   Western Europe\n",
            "111                    Iraq  Middle East and Northern Africa\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values\n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"Make\"].isnull().values.any()`  \n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values\n",
        "---\n",
        "\n",
        "1. read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\n",
        "2. check if any NA values exist in the dataframe and print the result\n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
        "\n",
        "**Test output**:\n",
        "True\n",
        ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474ce729-155c-478d-88ff-ad83d671cc23"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Check if any NA values exist in the dataframe and print the result\n",
        "  check_data = data.isnull().values.any()\n",
        "\n",
        "  # 2. Use df.info() to see which columns have null entries\n",
        "  null_entries = data.info()\n",
        "\n",
        "  return {\n",
        "      \"1. Check if any NA values exist in the dataframe and print the result\": check_data,\n",
        "      \"2. Use df.info() to see which columns have null entries\": null_entries,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 4 - Check for null values\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n",
            "\n",
            "Exercise 4 - Check for null values\n",
            "\n",
            "1. Check if any NA values exist in the dataframe and print the result:\n",
            "True\n",
            "\n",
            "2. Use df.info() to see which columns have null entries:\n",
            "None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values\n",
        "---\n",
        "\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
        "2. remove all NA values across whole dataframe\n",
        "\n",
        "**Test output**:  \n",
        "1.  Row count reduced to 352 rows\n",
        "2.  Row count reduced to 267 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a109b71-ca0b-4e6f-89c6-b51b97afca59"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Display whole dataframe, with all the NA values\"\n",
        "  full_df = data.loc[:]\n",
        "\n",
        "  # 2. Remove rows with NA values for \"life_satisfaction\"\n",
        "  new_life_satis = data.dropna(subset = [\"life_satisfaction\"])\n",
        "\n",
        "  # 3. Remove all NA values across whole dataframe\n",
        "  rem_all_na = data.dropna()\n",
        "\n",
        "  return {\n",
        "      \"1. Display whole dataframe, with all the NA values\": full_df,\n",
        "      \"2. Remove rows with NA values for \\\"life_satisfaction\\\"\": new_life_satis,\n",
        "      \"3. Remove all NA values across whole dataframe\": rem_all_na,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 5 - Remove null values\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 5 - Remove null values\n",
            "\n",
            "1. Display whole dataframe, with all the NA values:\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag\n",
            "0     E09000001        city of london  1999-12-01        33020.0                NaN       48922             0           6581.0             NaN        NaN           NaN             1\n",
            "1     E09000002  barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0             NaN        NaN           NaN             1\n",
            "2     E09000003                barnet  1999-12-01        19568.0                NaN       23128             8         313469.0             NaN        NaN           NaN             1\n",
            "3     E09000004                bexley  1999-12-01        18621.0                NaN       21386            18         217458.0             NaN        NaN           NaN             1\n",
            "4     E09000005                 brent  1999-12-01        18532.0                NaN       20911             6         260317.0             NaN        NaN           NaN             1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...        ...           ...           ...\n",
            "1066  K03000001         great britain  2019-12-01        30446.0                NaN       37603           NaN              NaN             NaN        NaN           NaN             0\n",
            "1067  K04000001     england and wales  2019-12-01        30500.0                NaN       37865           NaN              NaN             NaN        NaN           NaN             0\n",
            "1068  N92000002      northern ireland  2019-12-01        27434.0                NaN       32083           NaN              NaN             NaN        NaN           NaN             0\n",
            "1069  S92000003              scotland  2019-12-01        30000.0                NaN       34916           NaN              NaN             NaN        NaN           NaN             0\n",
            "1070  W92000004                 wales  2019-12-01        27500.0                NaN       31251           NaN              NaN             NaN        NaN           NaN             0\n",
            "\n",
            "[1071 rows x 12 columns]\n",
            "\n",
            "2. Remove rows with NA values for \"life_satisfaction\":\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs   area_size  no_of_houses  borough_flag\n",
            "613   E09000002  barking and dagenham  2011-12-01        28201.0               7.05       33568            30         187029.0         54000.0      3780.0       71079.0             1\n",
            "614   E09000003                barnet  2011-12-01        30237.0               7.43       33062            34         357538.0        147000.0      8675.0      139346.0             1\n",
            "615   E09000004                bexley  2011-12-01        28638.0               7.42       31812            54         232774.0         78000.0      6429.0       95037.0             1\n",
            "616   E09000005                 brent  2011-12-01        26772.0               7.11       29609            37         312245.0        115000.0      4323.0      112083.0             1\n",
            "617   E09000006               bromley  2011-12-01        28163.0               7.50       32863            50         310554.0        119000.0     15013.0      135036.0             1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...         ...           ...           ...\n",
            "1010  E12000009            south west  2018-12-01        27956.0               7.77       32848            50        5599735.0       3011000.0         NaN           NaN             0\n",
            "1013  E92000001               england  2018-12-01        29856.0               7.71       37313            44       55977178.0      30493000.0  13303728.0    24172166.0             0\n",
            "1017  N92000002      northern ireland  2018-12-01        27101.0               7.89       31158           NaN        1881641.0        900000.0         NaN           NaN             0\n",
            "1018  S92000003              scotland  2018-12-01        29289.0               7.69       34604           NaN        5438100.0       2861000.0         NaN           NaN             0\n",
            "1019  W92000004                 wales  2018-12-01        26353.0               7.68       30347           NaN        3138631.0       1496000.0         NaN           NaN             0\n",
            "\n",
            "[352 rows x 12 columns]\n",
            "\n",
            "3. Remove all NA values across whole dataframe:\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs   area_size  no_of_houses  borough_flag\n",
            "613   E09000002  barking and dagenham  2011-12-01        28201.0               7.05       33568            30         187029.0         54000.0      3780.0       71079.0             1\n",
            "614   E09000003                barnet  2011-12-01        30237.0               7.43       33062            34         357538.0        147000.0      8675.0      139346.0             1\n",
            "615   E09000004                bexley  2011-12-01        28638.0               7.42       31812            54         232774.0         78000.0      6429.0       95037.0             1\n",
            "616   E09000005                 brent  2011-12-01        26772.0               7.11       29609            37         312245.0        115000.0      4323.0      112083.0             1\n",
            "617   E09000006               bromley  2011-12-01        28163.0               7.50       32863            50         310554.0        119000.0     15013.0      135036.0             1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...         ...           ...           ...\n",
            "999   E09000031        waltham forest  2018-12-01        30298.0               7.46       32875            32         276700.0         88000.0      3881.0      103029.0             1\n",
            "1000  E09000032            wandsworth  2018-12-01        34501.0               7.65       45317            23         326474.0        147000.0      3522.0      146162.0             1\n",
            "1001  E09000033           westminster  2018-12-01        43015.0               7.66       63792            22         255324.0        775000.0      2203.0      124509.0             1\n",
            "1008  E12000007                london  2018-12-01        38146.0               7.58       52629            33        8908081.0       6148000.0    159471.0     3556161.0             0\n",
            "1013  E92000001               england  2018-12-01        29856.0               7.71       37313            44       55977178.0      30493000.0  13303728.0    24172166.0             0\n",
            "\n",
            "[267 rows x 12 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])`\n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries\n",
        "---\n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n",
        "\n",
        "**Test output**:  \n",
        " Dataframe now contains 50 rows all with date 1999-12-*01*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e52357-b915-48d2-d2d6-b0b5d8977928"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Display whole dataframe, with all the NA values\"\n",
        "  full_df = data.loc[:]\n",
        "\n",
        "  # 2. Remove duplicate \"area\" entries\n",
        "  rem_dupl_area = data.drop_duplicates(subset = [\"area\"])\n",
        "\n",
        "  # 3. Remove rows with NA values in the \"median_salary\" column\n",
        "  rem_na_med_sal = rem_dupl_area.dropna(subset = [\"median_salary\"])\n",
        "\n",
        "  return {\n",
        "      \"1. Display whole dataframe, with all the NA values\": full_df,\n",
        "      \"2. Remove duplicate \\\"area\\\" entries\": rem_dupl_area,\n",
        "      \"3. Remove rows with NA values in the \\\"median_salary\\\" column\": rem_na_med_sal,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 6 - Removing duplicate entries\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 6 - Removing duplicate entries\n",
            "\n",
            "1. Display whole dataframe, with all the NA values:\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag\n",
            "0     E09000001        city of london  1999-12-01        33020.0                NaN       48922             0           6581.0             NaN        NaN           NaN             1\n",
            "1     E09000002  barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0             NaN        NaN           NaN             1\n",
            "2     E09000003                barnet  1999-12-01        19568.0                NaN       23128             8         313469.0             NaN        NaN           NaN             1\n",
            "3     E09000004                bexley  1999-12-01        18621.0                NaN       21386            18         217458.0             NaN        NaN           NaN             1\n",
            "4     E09000005                 brent  1999-12-01        18532.0                NaN       20911             6         260317.0             NaN        NaN           NaN             1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...        ...           ...           ...\n",
            "1066  K03000001         great britain  2019-12-01        30446.0                NaN       37603           NaN              NaN             NaN        NaN           NaN             0\n",
            "1067  K04000001     england and wales  2019-12-01        30500.0                NaN       37865           NaN              NaN             NaN        NaN           NaN             0\n",
            "1068  N92000002      northern ireland  2019-12-01        27434.0                NaN       32083           NaN              NaN             NaN        NaN           NaN             0\n",
            "1069  S92000003              scotland  2019-12-01        30000.0                NaN       34916           NaN              NaN             NaN        NaN           NaN             0\n",
            "1070  W92000004                 wales  2019-12-01        27500.0                NaN       31251           NaN              NaN             NaN        NaN           NaN             0\n",
            "\n",
            "[1071 rows x 12 columns]\n",
            "\n",
            "2. Remove duplicate \"area\" entries:\n",
            "         code                      area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag\n",
            "0   E09000001            city of london  1999-12-01        33020.0                NaN       48922             0           6581.0             NaN        NaN           NaN             1\n",
            "1   E09000002      barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0             NaN        NaN           NaN             1\n",
            "2   E09000003                    barnet  1999-12-01        19568.0                NaN       23128             8         313469.0             NaN        NaN           NaN             1\n",
            "3   E09000004                    bexley  1999-12-01        18621.0                NaN       21386            18         217458.0             NaN        NaN           NaN             1\n",
            "4   E09000005                     brent  1999-12-01        18532.0                NaN       20911             6         260317.0             NaN        NaN           NaN             1\n",
            "5   E09000006                   bromley  1999-12-01        16720.0                NaN       21293            13         294902.0             NaN        NaN           NaN             1\n",
            "6   E09000007                    camden  1999-12-01        23677.0                NaN       30249            13         190003.0             NaN        NaN           NaN             1\n",
            "7   E09000008                   croydon  1999-12-01        19563.0                NaN       22205            13         332066.0             NaN        NaN           NaN             1\n",
            "8   E09000009                    ealing  1999-12-01        20580.0                NaN       25046            12         302252.0             NaN        NaN           NaN             1\n",
            "9   E09000010                   enfield  1999-12-01        19289.0                NaN       21006             9         272731.0             NaN        NaN           NaN             1\n",
            "10  E09000011                 greenwich  1999-12-01        21236.0                NaN       22263             4         212168.0             NaN        NaN           NaN             1\n",
            "11  E09000012                   hackney  1999-12-01        23249.0                NaN       39629             2         199087.0             NaN        NaN           NaN             1\n",
            "12  E09000013    hammersmith and fulham  1999-12-01        25000.0                NaN       28555             7         160634.0             NaN        NaN           NaN             1\n",
            "13  E09000014                  haringey  1999-12-01        18783.0                NaN       21683             5         218559.0             NaN        NaN           NaN             1\n",
            "14  E09000015                    harrow  1999-12-01        20596.0                NaN       22824            10         207909.0             NaN        NaN           NaN             1\n",
            "15  E09000016                  havering  1999-12-01        17165.0                NaN       18786             8         225712.0             NaN        NaN           NaN             1\n",
            "16  E09000017                hillingdon  1999-12-01        24002.0                NaN       28854            11         245053.0             NaN        NaN           NaN             1\n",
            "17  E09000018                  hounslow  1999-12-01        20155.0                NaN       24602            14         214298.0             NaN        NaN           NaN             1\n",
            "18  E09000019                 islington  1999-12-01        25113.0                NaN       34180             2         175717.0             NaN        NaN           NaN             1\n",
            "19  E09000020    kensington and chelsea  1999-12-01        20646.0                NaN       28074            13         147678.0             NaN        NaN           NaN             1\n",
            "20  E09000021      kingston upon thames  1999-12-01        19302.0                NaN       22967            18         146003.0             NaN        NaN           NaN             1\n",
            "21  E09000022                   lambeth  1999-12-01        23151.0                NaN       27930             8         266817.0             NaN        NaN           NaN             1\n",
            "22  E09000023                  lewisham  1999-12-01        20580.0                NaN       23283             4         250310.0             NaN        NaN           NaN             1\n",
            "23  E09000024                    merton  1999-12-01        18962.0                NaN       21867            11         185062.0             NaN        NaN           NaN             1\n",
            "24  E09000025                    newham  1999-12-01        18862.0                NaN       20580             3         240517.0             NaN        NaN           NaN             1\n",
            "25  E09000026                 redbridge  1999-12-01        19580.0                NaN       22087             8         238138.0             NaN        NaN           NaN             1\n",
            "26  E09000027      richmond upon thames  1999-12-01        22321.0                NaN       25832            na         172782.0             NaN        NaN           NaN             1\n",
            "27  E09000028                 southwark  1999-12-01        22784.0                NaN       26994             3         247853.0             NaN        NaN           NaN             1\n",
            "28  E09000029                    sutton  1999-12-01        19582.0                NaN       22725            27         179375.0             NaN        NaN           NaN             1\n",
            "29  E09000030             tower hamlets  1999-12-01        26376.0                NaN       37524             3         193507.0             NaN        NaN           NaN             1\n",
            "30  E09000031            waltham forest  1999-12-01        18547.0                NaN       19888             9         221057.0             NaN        NaN           NaN             1\n",
            "31  E09000032                wandsworth  1999-12-01        21321.0                NaN       24707             7         264220.0             NaN        NaN           NaN             1\n",
            "32  E09000033               westminster  1999-12-01        24447.0                NaN       36167             7         189233.0             NaN        NaN           NaN             1\n",
            "33  E12000001                north east  1999-12-01        16282.0                NaN       18351             5        2550314.0             NaN        NaN           NaN             0\n",
            "34  E12000002                north west  1999-12-01        16977.0                NaN       19609             7        6773115.0             NaN        NaN           NaN             0\n",
            "35  E12000003  yorkshire and the humber  1999-12-01        16527.0                NaN       18977             7        4956325.0             NaN        NaN           NaN             0\n",
            "36  E12000004             east midlands  1999-12-01        16392.0                NaN       18864            11        4152443.0             NaN        NaN           NaN             0\n",
            "37  E12000005             west midlands  1999-12-01        17000.0                NaN       19686             9        5271959.0             NaN        NaN           NaN             0\n",
            "38  E12000006                      east  1999-12-01        18000.0                NaN       20866            14        5338722.0             NaN        NaN           NaN             0\n",
            "39  E12000007                    london  1999-12-01        22487.0                NaN       29640             9        7153912.0             NaN        NaN           NaN             0\n",
            "40  E12000008                south east  1999-12-01        18737.0                NaN       22361            15        7955124.0             NaN        NaN           NaN             0\n",
            "41  E12000009                south west  1999-12-01        16727.0                NaN       19203            14        4880958.0             NaN        NaN           NaN             0\n",
            "42  E13000001              inner london  1999-12-01            NaN                NaN           -           NaN        2750716.0             NaN        NaN           NaN             0\n",
            "43  E13000002              outer london  1999-12-01            NaN                NaN           -           NaN        4403196.0             NaN        NaN           NaN             0\n",
            "44  E92000001                   england  1999-12-01        17939.0                NaN       21561            10       49032872.0             NaN        NaN           NaN             0\n",
            "45  K02000001            united kingdom  1999-12-01        17803.0                NaN       21314           NaN       58684427.0             NaN        NaN           NaN             0\n",
            "46  K03000001             great britain  1999-12-01        17866.0                NaN       21379           NaN       57005421.0             NaN        NaN           NaN             0\n",
            "47  K04000001         england and wales  1999-12-01        17974.0                NaN       21549           NaN       51933471.0             NaN        NaN           NaN             0\n",
            "48  N92000002          northern ireland  1999-12-01        15798.0                NaN       19093           NaN        1679006.0             NaN        NaN           NaN             0\n",
            "49  S92000003                  scotland  1999-12-01        16914.0                NaN       19667           NaN        5071950.0             NaN        NaN           NaN             0\n",
            "50  W92000004                     wales  1999-12-01        16457.0                NaN       18486           NaN        2900599.0             NaN        NaN           NaN             0\n",
            "\n",
            "3. Remove rows with NA values in the \"median_salary\" column:\n",
            "         code                      area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag\n",
            "0   E09000001            city of london  1999-12-01        33020.0                NaN       48922             0           6581.0             NaN        NaN           NaN             1\n",
            "1   E09000002      barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0             NaN        NaN           NaN             1\n",
            "2   E09000003                    barnet  1999-12-01        19568.0                NaN       23128             8         313469.0             NaN        NaN           NaN             1\n",
            "3   E09000004                    bexley  1999-12-01        18621.0                NaN       21386            18         217458.0             NaN        NaN           NaN             1\n",
            "4   E09000005                     brent  1999-12-01        18532.0                NaN       20911             6         260317.0             NaN        NaN           NaN             1\n",
            "5   E09000006                   bromley  1999-12-01        16720.0                NaN       21293            13         294902.0             NaN        NaN           NaN             1\n",
            "6   E09000007                    camden  1999-12-01        23677.0                NaN       30249            13         190003.0             NaN        NaN           NaN             1\n",
            "7   E09000008                   croydon  1999-12-01        19563.0                NaN       22205            13         332066.0             NaN        NaN           NaN             1\n",
            "8   E09000009                    ealing  1999-12-01        20580.0                NaN       25046            12         302252.0             NaN        NaN           NaN             1\n",
            "9   E09000010                   enfield  1999-12-01        19289.0                NaN       21006             9         272731.0             NaN        NaN           NaN             1\n",
            "10  E09000011                 greenwich  1999-12-01        21236.0                NaN       22263             4         212168.0             NaN        NaN           NaN             1\n",
            "11  E09000012                   hackney  1999-12-01        23249.0                NaN       39629             2         199087.0             NaN        NaN           NaN             1\n",
            "12  E09000013    hammersmith and fulham  1999-12-01        25000.0                NaN       28555             7         160634.0             NaN        NaN           NaN             1\n",
            "13  E09000014                  haringey  1999-12-01        18783.0                NaN       21683             5         218559.0             NaN        NaN           NaN             1\n",
            "14  E09000015                    harrow  1999-12-01        20596.0                NaN       22824            10         207909.0             NaN        NaN           NaN             1\n",
            "15  E09000016                  havering  1999-12-01        17165.0                NaN       18786             8         225712.0             NaN        NaN           NaN             1\n",
            "16  E09000017                hillingdon  1999-12-01        24002.0                NaN       28854            11         245053.0             NaN        NaN           NaN             1\n",
            "17  E09000018                  hounslow  1999-12-01        20155.0                NaN       24602            14         214298.0             NaN        NaN           NaN             1\n",
            "18  E09000019                 islington  1999-12-01        25113.0                NaN       34180             2         175717.0             NaN        NaN           NaN             1\n",
            "19  E09000020    kensington and chelsea  1999-12-01        20646.0                NaN       28074            13         147678.0             NaN        NaN           NaN             1\n",
            "20  E09000021      kingston upon thames  1999-12-01        19302.0                NaN       22967            18         146003.0             NaN        NaN           NaN             1\n",
            "21  E09000022                   lambeth  1999-12-01        23151.0                NaN       27930             8         266817.0             NaN        NaN           NaN             1\n",
            "22  E09000023                  lewisham  1999-12-01        20580.0                NaN       23283             4         250310.0             NaN        NaN           NaN             1\n",
            "23  E09000024                    merton  1999-12-01        18962.0                NaN       21867            11         185062.0             NaN        NaN           NaN             1\n",
            "24  E09000025                    newham  1999-12-01        18862.0                NaN       20580             3         240517.0             NaN        NaN           NaN             1\n",
            "25  E09000026                 redbridge  1999-12-01        19580.0                NaN       22087             8         238138.0             NaN        NaN           NaN             1\n",
            "26  E09000027      richmond upon thames  1999-12-01        22321.0                NaN       25832            na         172782.0             NaN        NaN           NaN             1\n",
            "27  E09000028                 southwark  1999-12-01        22784.0                NaN       26994             3         247853.0             NaN        NaN           NaN             1\n",
            "28  E09000029                    sutton  1999-12-01        19582.0                NaN       22725            27         179375.0             NaN        NaN           NaN             1\n",
            "29  E09000030             tower hamlets  1999-12-01        26376.0                NaN       37524             3         193507.0             NaN        NaN           NaN             1\n",
            "30  E09000031            waltham forest  1999-12-01        18547.0                NaN       19888             9         221057.0             NaN        NaN           NaN             1\n",
            "31  E09000032                wandsworth  1999-12-01        21321.0                NaN       24707             7         264220.0             NaN        NaN           NaN             1\n",
            "32  E09000033               westminster  1999-12-01        24447.0                NaN       36167             7         189233.0             NaN        NaN           NaN             1\n",
            "33  E12000001                north east  1999-12-01        16282.0                NaN       18351             5        2550314.0             NaN        NaN           NaN             0\n",
            "34  E12000002                north west  1999-12-01        16977.0                NaN       19609             7        6773115.0             NaN        NaN           NaN             0\n",
            "35  E12000003  yorkshire and the humber  1999-12-01        16527.0                NaN       18977             7        4956325.0             NaN        NaN           NaN             0\n",
            "36  E12000004             east midlands  1999-12-01        16392.0                NaN       18864            11        4152443.0             NaN        NaN           NaN             0\n",
            "37  E12000005             west midlands  1999-12-01        17000.0                NaN       19686             9        5271959.0             NaN        NaN           NaN             0\n",
            "38  E12000006                      east  1999-12-01        18000.0                NaN       20866            14        5338722.0             NaN        NaN           NaN             0\n",
            "39  E12000007                    london  1999-12-01        22487.0                NaN       29640             9        7153912.0             NaN        NaN           NaN             0\n",
            "40  E12000008                south east  1999-12-01        18737.0                NaN       22361            15        7955124.0             NaN        NaN           NaN             0\n",
            "41  E12000009                south west  1999-12-01        16727.0                NaN       19203            14        4880958.0             NaN        NaN           NaN             0\n",
            "44  E92000001                   england  1999-12-01        17939.0                NaN       21561            10       49032872.0             NaN        NaN           NaN             0\n",
            "45  K02000001            united kingdom  1999-12-01        17803.0                NaN       21314           NaN       58684427.0             NaN        NaN           NaN             0\n",
            "46  K03000001             great britain  1999-12-01        17866.0                NaN       21379           NaN       57005421.0             NaN        NaN           NaN             0\n",
            "47  K04000001         england and wales  1999-12-01        17974.0                NaN       21549           NaN       51933471.0             NaN        NaN           NaN             0\n",
            "48  N92000002          northern ireland  1999-12-01        15798.0                NaN       19093           NaN        1679006.0             NaN        NaN           NaN             0\n",
            "49  S92000003                  scotland  1999-12-01        16914.0                NaN       19667           NaN        5071950.0             NaN        NaN           NaN             0\n",
            "50  W92000004                     wales  1999-12-01        16457.0                NaN       18486           NaN        2900599.0             NaN        NaN           NaN             0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "# Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
        "\n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "To normalise we need to:\n",
        "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
        "\n",
        "For example:  \n",
        "```\n",
        "def normalise_bmi(df):\n",
        "  if df['bmi'] >= 25:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
        "```\n",
        "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8KPmy2_NVh1"
      },
      "source": [
        "### Exercise 7 - normalise data set\n",
        "---\n",
        "\n",
        "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
        "\n",
        "Apply the normalise_income(df) function to the `median_salary` column.\n",
        "\n",
        "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktylpCl7QjGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2709186a-7d74-4397-c76b-6744b366a8cc"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "# Interrogate data\n",
        "def normalise_income(data):\n",
        "  if data[\"median_salary\"] < 27441:\n",
        "    return 1\n",
        "  elif data[\"median_salary\"] < 30932:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "data[\"median_salary\"] = data.apply(normalise_income, axis = 1)\n",
        "\n",
        "print(\"\\nExercise 7 - Normalise data set\\n\")\n",
        "print(data.loc[:])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 7 - Normalise data set\n",
            "\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag\n",
            "0     E09000001        city of london  1999-12-01              3                NaN       48922             0           6581.0             NaN        NaN           NaN             1\n",
            "1     E09000002  barking and dagenham  1999-12-01              1                NaN       23620             3         162444.0             NaN        NaN           NaN             1\n",
            "2     E09000003                barnet  1999-12-01              1                NaN       23128             8         313469.0             NaN        NaN           NaN             1\n",
            "3     E09000004                bexley  1999-12-01              1                NaN       21386            18         217458.0             NaN        NaN           NaN             1\n",
            "4     E09000005                 brent  1999-12-01              1                NaN       20911             6         260317.0             NaN        NaN           NaN             1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...        ...           ...           ...\n",
            "1066  K03000001         great britain  2019-12-01              2                NaN       37603           NaN              NaN             NaN        NaN           NaN             0\n",
            "1067  K04000001     england and wales  2019-12-01              2                NaN       37865           NaN              NaN             NaN        NaN           NaN             0\n",
            "1068  N92000002      northern ireland  2019-12-01              1                NaN       32083           NaN              NaN             NaN        NaN           NaN             0\n",
            "1069  S92000003              scotland  2019-12-01              2                NaN       34916           NaN              NaN             NaN        NaN           NaN             0\n",
            "1070  W92000004                 wales  2019-12-01              2                NaN       31251           NaN              NaN             NaN        NaN           NaN             0\n",
            "\n",
            "[1071 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrIEyMjSYTI"
      },
      "source": [
        "### Exercise 8 - normalise the number of jobs column\n",
        "---\n",
        "\n",
        "Using what you have learnt from Exercise 7:  \n",
        "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
        "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
        "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYXovr-T7TB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaebbf8b-8cbe-49db-a982-8a1e413cf629"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "# Interrogate data\n",
        "# 1. Use df.describe() to find the median, upper quartile and maximum for the \"number_of_jobs\" column\n",
        "stats = data[\"number_of_jobs\"].describe()\n",
        "\n",
        "# Median\n",
        "median = stats[\"50%\"]\n",
        "\n",
        "# Upper Quartile\n",
        "upper_quartile = stats[\"75%\"]\n",
        "\n",
        "#  Maximum\n",
        "max = stats[\"max\"]\n",
        "\n",
        "print(\"\\nExercise 8 - Normalise the number of jobs column\")\n",
        "print(f\"\\nUse .describe() to find the median, upper quartile and maximum for the \\\"number_of_jobs\\\" column:\\n{stats}\\n\")\n",
        "print(f\"\\nDisplay Median, Upper Quartile and Maximum:\\nMedian: {median}\\nUpper Quartile: {upper_quartile}\\nMaximum: {max}\\n\")\n",
        "\n",
        "# 2. Create a function called normalise_jobs(df) that will return 1 if the \"number_of_jobs\" is below the median, 2 if the \"number_of_jobs\" is below the upper quartile or 3 otherwise.\n",
        "def normalise_jobs(data):\n",
        "  if data[\"number_of_jobs\"] < median:\n",
        "    return 1\n",
        "  elif data[\"number_of_jobs\"] < upper_quartile:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "# 3. Normalise the \"number_of_jobs\" column by applying the function normalise_jobs.\n",
        "\n",
        "data[\"number_of_jobs\"] = data.apply(normalise_jobs, axis = 1)\n",
        "\n",
        "print(f\"\\nDisplay normalised \\\"number_of_jobs\\\" column:\\n{data.loc[:]}\\n\")\n",
        "\n",
        "stats2 = data[\"number_of_jobs\"].describe()\n",
        "print(f\"\\nDescribe normalised \\\"number_of_jobs\\\" column:\\n{stats2}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 8 - Normalise the number of jobs column\n",
            "\n",
            "Use .describe() to find the median, upper quartile and maximum for the \"number_of_jobs\" column:\n",
            "count    9.310000e+02\n",
            "mean     3.188095e+06\n",
            "std      8.058302e+06\n",
            "min      4.700000e+04\n",
            "25%      9.450000e+04\n",
            "50%      1.570000e+05\n",
            "75%      2.217000e+06\n",
            "max      3.575000e+07\n",
            "Name: number_of_jobs, dtype: float64\n",
            "\n",
            "\n",
            "Display Median, Upper Quartile and Maximum:\n",
            "Median: 157000.0\n",
            "Upper Quartile: 2217000.0\n",
            "Maximum: 35750000.0\n",
            "\n",
            "\n",
            "Display normalised \"number_of_jobs\" column:\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag\n",
            "0     E09000001        city of london  1999-12-01        33020.0                NaN       48922             0           6581.0               3        NaN           NaN             1\n",
            "1     E09000002  barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0               3        NaN           NaN             1\n",
            "2     E09000003                barnet  1999-12-01        19568.0                NaN       23128             8         313469.0               3        NaN           NaN             1\n",
            "3     E09000004                bexley  1999-12-01        18621.0                NaN       21386            18         217458.0               3        NaN           NaN             1\n",
            "4     E09000005                 brent  1999-12-01        18532.0                NaN       20911             6         260317.0               3        NaN           NaN             1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...        ...           ...           ...\n",
            "1066  K03000001         great britain  2019-12-01        30446.0                NaN       37603           NaN              NaN               3        NaN           NaN             0\n",
            "1067  K04000001     england and wales  2019-12-01        30500.0                NaN       37865           NaN              NaN               3        NaN           NaN             0\n",
            "1068  N92000002      northern ireland  2019-12-01        27434.0                NaN       32083           NaN              NaN               3        NaN           NaN             0\n",
            "1069  S92000003              scotland  2019-12-01        30000.0                NaN       34916           NaN              NaN               3        NaN           NaN             0\n",
            "1070  W92000004                 wales  2019-12-01        27500.0                NaN       31251           NaN              NaN               3        NaN           NaN             0\n",
            "\n",
            "[1071 rows x 12 columns]\n",
            "\n",
            "\n",
            "Describe normalised \"number_of_jobs\" column:\n",
            "count    1071.000000\n",
            "mean        1.914099\n",
            "std         0.880790\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         2.000000\n",
            "75%         3.000000\n",
            "max         3.000000\n",
            "Name: number_of_jobs, dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akqnUbYVblH"
      },
      "source": [
        "## Exercise 9 - normalise into a new column\n",
        "---\n",
        "\n",
        "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQsE4znV6nD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91fed520-d0ec-4d48-b1bb-eb2132581a22"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "# Interrogate data\n",
        "# 1. Use df.describe() to find the median, upper quartile and maximum for the \"number_of_jobs\" column\n",
        "house_stats = data[\"no_of_houses\"].describe()\n",
        "\n",
        "# Median\n",
        "median = house_stats[\"50%\"]\n",
        "\n",
        "# Upper Quartile\n",
        "upper_quartile = house_stats[\"75%\"]\n",
        "\n",
        "#  Maximum\n",
        "max = house_stats[\"max\"]\n",
        "\n",
        "# 2. Create a new function and code to normalise the \"no_of_houses\" column.\n",
        "def normalise_house_nos(data):\n",
        "  if data[\"no_of_houses\"] < median:\n",
        "    return 1\n",
        "  elif data[\"no_of_houses\"] < upper_quartile:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "# 3. Normalise the \"no_of_houses\" column by applying the function normalise_jobs. Assign it to a new column called df['housing_volume']\n",
        "data[\"housing_volume\"] = data.apply(normalise_house_nos, axis = 1)\n",
        "\n",
        "print(f\"\\nDisplay normalised \\\"housing_volume\\\" column:\\n{data.loc[:]}\\n\")\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Display normalised \"housing_volume\" column:\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag  housing_volume\n",
            "0     E09000001        city of london  1999-12-01        33020.0                NaN       48922             0           6581.0             NaN        NaN           NaN             1               3\n",
            "1     E09000002  barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0             NaN        NaN           NaN             1               3\n",
            "2     E09000003                barnet  1999-12-01        19568.0                NaN       23128             8         313469.0             NaN        NaN           NaN             1               3\n",
            "3     E09000004                bexley  1999-12-01        18621.0                NaN       21386            18         217458.0             NaN        NaN           NaN             1               3\n",
            "4     E09000005                 brent  1999-12-01        18532.0                NaN       20911             6         260317.0             NaN        NaN           NaN             1               3\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...        ...           ...           ...             ...\n",
            "1066  K03000001         great britain  2019-12-01        30446.0                NaN       37603           NaN              NaN             NaN        NaN           NaN             0               3\n",
            "1067  K04000001     england and wales  2019-12-01        30500.0                NaN       37865           NaN              NaN             NaN        NaN           NaN             0               3\n",
            "1068  N92000002      northern ireland  2019-12-01        27434.0                NaN       32083           NaN              NaN             NaN        NaN           NaN             0               3\n",
            "1069  S92000003              scotland  2019-12-01        30000.0                NaN       34916           NaN              NaN             NaN        NaN           NaN             0               3\n",
            "1070  W92000004                 wales  2019-12-01        27500.0                NaN       31251           NaN              NaN             NaN        NaN           NaN             0               3\n",
            "\n",
            "[1071 rows x 13 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FaL31EXHZX"
      },
      "source": [
        "### Exercise 10 - normalise boroughs\n",
        "---\n",
        "\n",
        "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
        "\n",
        "**Test output**:  \n",
        "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIZ9M0UXkkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1e747d-a9c0-40d0-f89b-f76a82eaaf15"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_csv_data():\n",
        "  url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "  df = pd.read_csv(url)\n",
        "  return df\n",
        "\n",
        "data = get_csv_data()\n",
        "\n",
        "\n",
        "# Interrogate data\n",
        "# 1. Normalise the \"area_size\" column so that all values below mean are represented as 0 and otherwise are 1.\n",
        "mean = data[\"area_size\"].mean()\n",
        "\n",
        "def area_size_normalised(data):\n",
        "  if data[\"area_size\"] < mean:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "# 2. Assign the output to a new column called \"area_size_normalised\".\n",
        "data[\"area_size_normalised\"] = data.apply(area_size_normalised, axis = 1)\n",
        "\n",
        "print(f\"\\nDisplay normalised \\\"area_size\\\" column:\\n{data.loc[:]}\\n\")\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    6.660000e+02\n",
            "mean     3.724903e+05\n",
            "std      2.157060e+06\n",
            "min      3.150000e+02\n",
            "25%      2.960000e+03\n",
            "50%      4.323000e+03\n",
            "75%      8.220000e+03\n",
            "max      1.330373e+07\n",
            "Name: area_size, dtype: float64\n",
            "\n",
            "Display normalised \"area_size\" column:\n",
            "           code                  area        date  median_salary  life_satisfaction mean_salary recycling_pct  population_size  number_of_jobs  area_size  no_of_houses  borough_flag  area_size_normalised\n",
            "0     E09000001        city of london  1999-12-01        33020.0                NaN       48922             0           6581.0             NaN        NaN           NaN             1                     1\n",
            "1     E09000002  barking and dagenham  1999-12-01        21480.0                NaN       23620             3         162444.0             NaN        NaN           NaN             1                     1\n",
            "2     E09000003                barnet  1999-12-01        19568.0                NaN       23128             8         313469.0             NaN        NaN           NaN             1                     1\n",
            "3     E09000004                bexley  1999-12-01        18621.0                NaN       21386            18         217458.0             NaN        NaN           NaN             1                     1\n",
            "4     E09000005                 brent  1999-12-01        18532.0                NaN       20911             6         260317.0             NaN        NaN           NaN             1                     1\n",
            "...         ...                   ...         ...            ...                ...         ...           ...              ...             ...        ...           ...           ...                   ...\n",
            "1066  K03000001         great britain  2019-12-01        30446.0                NaN       37603           NaN              NaN             NaN        NaN           NaN             0                     1\n",
            "1067  K04000001     england and wales  2019-12-01        30500.0                NaN       37865           NaN              NaN             NaN        NaN           NaN             0                     1\n",
            "1068  N92000002      northern ireland  2019-12-01        27434.0                NaN       32083           NaN              NaN             NaN        NaN           NaN             0                     1\n",
            "1069  S92000003              scotland  2019-12-01        30000.0                NaN       34916           NaN              NaN             NaN        NaN           NaN             0                     1\n",
            "1070  W92000004                 wales  2019-12-01        27500.0                NaN       31251           NaN              NaN             NaN        NaN           NaN             0                     1\n",
            "\n",
            "[1071 rows x 13 columns]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}