{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TsamayaDesigns/codeDivision-data-with-python/blob/main/Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first.\n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g.\n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make\n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df` *original dataframe, df, will be as it was - unsorted*\n",
        "\n",
        "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score\n",
        "---\n",
        "\n",
        "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n",
        "**Test output**:  \n",
        "The lowest score (displayed first) is 2.839, Togo  \n",
        "The highest score (displayed last) is 7.587, Switzerland  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4980cc-1db2-4b42-acd4-1f953a006689"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_excel_data():\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  return df\n",
        "\n",
        "data = get_excel_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Display first 5 rows of data\n",
        "  orig_data = data.head()\n",
        "\n",
        "  # 2. Sort the data by Happiness Score in ascending order & display the sorted table\n",
        "  sorted_data = data.sort_values(\"Happiness Score\", ascending = True)\n",
        "\n",
        "  return {\n",
        "      \"1. Display first 5 rows of data\": orig_data,\n",
        "      \"2. Display the sorted data - (by Happiness Score, sorted: ascending order)\": sorted_data,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 1 - Get data & Sort by Happiness Score\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 1 - Get data & Sort by Hapiness Score\n",
            "\n",
            "1. Display first 5 rows of data:\n",
            "       Country          Region  Happiness Rank  Happiness Score  Standard Error  Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  Trust (Government Corruption)  Generosity  Dystopia Residual\n",
            "0  Switzerland  Western Europe               1            7.587         0.03411                   1.39651  1.34951                   0.94143  0.66557                        0.41978     0.29678            2.51738\n",
            "1      Iceland  Western Europe               2            7.561         0.04884                   1.30232  1.40223                   0.94784  0.62877                        0.14145     0.43630            2.70201\n",
            "2      Denmark  Western Europe               3            7.527         0.03328                   1.32548  1.36058                   0.87464  0.64938                        0.48357     0.34139            2.49204\n",
            "3       Norway  Western Europe               4            7.522         0.03880                   1.45900  1.33095                   0.88521  0.66973                        0.36503     0.34699            2.46531\n",
            "4       Canada   North America               5            7.427         0.03553                   1.32629  1.32261                   0.90563  0.63297                        0.32957     0.45811            2.45176\n",
            "\n",
            "2. Display the sorted data - (by Happiness Score, sorted: ascending order):\n",
            "         Country                           Region  Happiness Rank  Happiness Score  Standard Error  Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  Trust (Government Corruption)  Generosity  Dystopia Residual\n",
            "157         Togo               Sub-Saharan Africa             158            2.839         0.06727                   0.20868  0.13995                   0.28443  0.36453                        0.10731     0.16681            1.56726\n",
            "156      Burundi               Sub-Saharan Africa             157            2.905         0.08658                   0.01530  0.41587                   0.22396  0.11850                        0.10062     0.19727            1.83302\n",
            "155        Syria  Middle East and Northern Africa             156            3.006         0.05015                   0.66320  0.47489                   0.72193  0.15684                        0.18906     0.47179            0.32858\n",
            "154        Benin               Sub-Saharan Africa             155            3.340         0.03656                   0.28665  0.35386                   0.31910  0.48450                        0.08010     0.18260            1.63328\n",
            "153       Rwanda               Sub-Saharan Africa             154            3.465         0.03464                   0.22208  0.77370                   0.42864  0.59201                        0.55191     0.22628            0.67042\n",
            "..           ...                              ...             ...              ...             ...                       ...      ...                       ...      ...                            ...         ...                ...\n",
            "4         Canada                    North America               5            7.427         0.03553                   1.32629  1.32261                   0.90563  0.63297                        0.32957     0.45811            2.45176\n",
            "3         Norway                   Western Europe               4            7.522         0.03880                   1.45900  1.33095                   0.88521  0.66973                        0.36503     0.34699            2.46531\n",
            "2        Denmark                   Western Europe               3            7.527         0.03328                   1.32548  1.36058                   0.87464  0.64938                        0.48357     0.34139            2.49204\n",
            "1        Iceland                   Western Europe               2            7.561         0.04884                   1.30232  1.40223                   0.94784  0.62877                        0.14145     0.43630            2.70201\n",
            "0    Switzerland                   Western Europe               1            7.587         0.03411                   1.39651  1.34951                   0.94143  0.66557                        0.41978     0.29678            2.51738\n",
            "\n",
            "[158 rows x 12 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows\n",
        "---\n",
        "\n",
        "1. Sort the data by Health (Life Expectancy) and Economy (GDP per Capita) in ascending order\n",
        "2. display the first 5 rows of sorted data\n",
        "\n",
        "**Test output**:  \n",
        "Records 122, 127, 147, 100, 96"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2309735c-2420-441b-9f50-91092ee1b774"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_excel_data():\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  return df\n",
        "\n",
        "data = get_excel_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Sort the data by Health (Life Expectancy) and Economy (GDP per Capita) in ascending order\n",
        "  sort_data = data.sort_values(by = [\"Health (Life Expectancy)\", \"Economy (GDP per Capita)\"], ascending = [True, True])\n",
        "\n",
        "  # 2. Display the first 5 rows of sorted data\n",
        "  sorted_data_hd = sort_data.head()\n",
        "\n",
        "  return {\n",
        "      \"1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order (first 5 rows of sorted data) \": sorted_data_hd,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 2 - Sort by multiple columns & display the first 5 rows\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 2 - Sort by multiple columns & display the first 5 rows\n",
            "\n",
            "1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order (first 5 rows of sorted data) :\n",
            "                      Country              Region  Happiness Rank  Happiness Score  Standard Error  Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  Trust (Government Corruption)  Generosity  Dystopia Residual\n",
            "122              Sierra Leone  Sub-Saharan Africa             123            4.507         0.07068                   0.33024  0.95571                   0.00000  0.40840                        0.08786     0.21488            2.51009\n",
            "127                  Botswana  Sub-Saharan Africa             128            4.332         0.04934                   0.99355  1.10464                   0.04776  0.49495                        0.12474     0.10461            1.46181\n",
            "147  Central African Republic  Sub-Saharan Africa             148            3.678         0.06112                   0.07850  0.00000                   0.06699  0.48879                        0.08289     0.23835            2.72230\n",
            "100                 Swaziland  Sub-Saharan Africa             101            4.867         0.08742                   0.71206  1.07284                   0.07566  0.30658                        0.03060     0.18259            2.48676\n",
            "96                    Lesotho  Sub-Saharan Africa              97            4.898         0.09438                   0.37545  1.04103                   0.07612  0.31767                        0.12504     0.16388            2.79832\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order\n",
        "---\n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n",
        "**Test output**:\n",
        "136, 117, 95, 101, 111 Country and Region columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356d7d66-5dac-4e51-f9a9-0064143f9993"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 240)\n",
        "\n",
        "def get_excel_data():\n",
        "  url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "  df = pd.read_excel(url)\n",
        "  return df\n",
        "\n",
        "data = get_excel_data()\n",
        "\n",
        "# Interrogate data\n",
        "def investigate_data(data):\n",
        "  # 1. Sort the data by Freedom and Trust (Government Corruption) in descending order. Show the Country and Region only for the last five rows\n",
        "  sort_data = data.sort_values(by = [\"Freedom\", \"Trust (Government Corruption)\"], ascending = False)[[\"Country\", \"Region\"]].tail()\n",
        "\n",
        "  return {\n",
        "      \"1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order\": sort_data,\n",
        "  }\n",
        "\n",
        "statistics = investigate_data(data)\n",
        "\n",
        "print(\"\\nExercise 3 - Sorting in descending order\\n\")\n",
        "for key, value in statistics.items():\n",
        "  print(f\"{key}:\\n{value}\\n\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exercise 3 - Sorting in descending order\n",
            "\n",
            "1. Display Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order:\n",
            "                    Country                           Region\n",
            "136                  Angola               Sub-Saharan Africa\n",
            "117                   Sudan               Sub-Saharan Africa\n",
            "95   Bosnia and Herzegovina       Central and Eastern Europe\n",
            "101                  Greece                   Western Europe\n",
            "111                    Iraq  Middle East and Northern Africa\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values\n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"Make\"].isnull().values.any()`  \n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values\n",
        "---\n",
        "\n",
        "1. read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\n",
        "2. check if any NA values exist in the dataframe and print the result\n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
        "\n",
        "**Test output**:\n",
        "True\n",
        ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values\n",
        "---\n",
        "\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
        "2. remove all NA values across whole dataframe\n",
        "\n",
        "**Test output**:  \n",
        "1.  Row count reduced to 352 rows\n",
        "2.  Row count reduced to 267 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])`\n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries\n",
        "---\n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n",
        "\n",
        "**Test output**:  \n",
        " Dataframe now contains 50 rows all with date 1999-12-*01*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "# Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
        "\n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "To normalise we need to:\n",
        "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
        "\n",
        "For example:  \n",
        "```\n",
        "def normalise_bmi(df):\n",
        "  if df['bmi'] >= 25:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
        "```\n",
        "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8KPmy2_NVh1"
      },
      "source": [
        "### Exercise 7 - normalise data set\n",
        "---\n",
        "\n",
        "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
        "\n",
        "Apply the normalise_income(df) function to the `median_salary` column.\n",
        "\n",
        "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktylpCl7QjGJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrIEyMjSYTI"
      },
      "source": [
        "### Exercise 8 - normalise the number of jobs column\n",
        "---\n",
        "\n",
        "Using what you have learnt from Exercise 7:  \n",
        "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
        "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
        "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYXovr-T7TB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akqnUbYVblH"
      },
      "source": [
        "## Exercise 9 - normalise into a new column\n",
        "---\n",
        "\n",
        "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQsE4znV6nD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FaL31EXHZX"
      },
      "source": [
        "### Exercise 10 - normalise boroughs\n",
        "---\n",
        "\n",
        "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
        "\n",
        "**Test output**:  \n",
        "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIZ9M0UXkkv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}